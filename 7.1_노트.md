# 키워드
잠재 디리클레 할당, 유사도

# Lesson 02
잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)
- 주어진 문서들에 대해 어떤 토픽들이 있는지 확률적으로 분류하는 기법.
- 문서의 단어 수 분포를 분석해서 어떤 주제인지 예측하게 된다.

두 가지 확률값
- P(단어 | 주제), P(주제 | 문서)
- 이 확률은 단어 X 주제, 주제 X 문서 행렬로 나타낼 수 있다고 함.

과정
- 사용자는 토픽 개수를 정하고, 알고리즘은 문서 내 모든 단어에 대해 토픽에 랜덤으로 할당.
- w와 d에 대해 iterate하면서 토픽에 대해 업데이트함
    - 위 두 가지 확률에 따라 iterate하는 단어 자신은 잘못 되었지만 다른 단어는 모두 올바른 토픽에 할당되어 있다고 가정하면서 업데이트
        - P(주제 t | 문서 d) 이 단어를 포함하는 문서 d 내에 단어들의 토픽의 비율을 보면서 업데이트
            - 문서 d에 존재하는 단어들이 토픽 t에 해당하는 비율
            - 현재 문서 d 내 현재 단어 w를 제외한 다른 단어들이 t에 해당하는 비율. 다른 단어들이 t에 해당하는 비율이 높다면 현 단어도 t에 해당할 가능성이 높다
        - P(단어 w | 주제 t) 이 단어에 할당된 토픽들의 비율을 보면서 업데이트
            - 모든 문서를 걸쳐 단어 w로 인해 토픽 t가 할당되는 확률
            - 단어 w를 가지고 있는 모든 문서들 중 토픽 t가 할당되는 비율
    - 이 둘을 결합 확률로 추정하여 토픽을 추정한다고 함.

LDA에서는 문서는 토픽들의 mixture. 토픽은 단어의 mixture. 특정 단어가 특정 토픽에 해당할 확률이 높다면 이 단어를 포함하는 문서들은 이 특정 토픽과 깊게 연관된다고 말할 수 있음.

# 코드 업데이트 필요
- 최신 버전 (3.4.1) pyLDAvis는 lda에 대해 scikit-learn과 관련된 로직이 `pyLDAvis.lda_model` 라이브러리 안에 있고, attribute들이 최신 sklearn과 호환된다. `pyLDAvis.sklearn`을 `pyLDAvis.lda_model`로 변경할 것

# 참고
[LDA 1](https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2)
[LDA 2](https://soojle.gitbook.io/project/requirements/undefined-1/undefined-3/lda)